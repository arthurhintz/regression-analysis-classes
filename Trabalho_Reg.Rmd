---
title: "Análise de Regressão na Produtividade de Soja"
author: "Arthur Hintz"
date: "`r format(Sys.time(), '%d %b %Y')`"
output:
  prettydoc::html_pretty:
    theme: architect
    number_sections: no
    toc: yes
    indent: true
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{css, echo = FALSE}
body {
  text-align: justify;
}
```

```{r, message=FALSE, include=FALSE}
library(wooldridge)
library(tidyverse)
library(hnp)
library(lmtest)
library(car) 
library(tseries)
library(corrplot)
library(knitr)
library(kableExtra)
library(skimr)
library(tidytext)
```

# Resumo

|       O trabalho tem como objetivo realizar uma análise de regressão linear múltipla para estimar a produtividade de soja em (Kg/ha) com base nos principais fatores que a influenciam. A análise será dividida em quatro etapas principais: análise descritiva, ajuste do modelo, diagnóstico de influência e teste das suposições do modelo.

# Introdução

|       Segundo a Confederação da Agricultura e Pecuária do Brasil (CNA), o Produto Interno Bruto (PIB) do Agronegócio corresponde a 23,8% em 2023, sendo a soja a commodity de maior valor de produção no Brasil, de acordo com dados divulgados pelo IBGE, [link de acesso](https://www.ibge.gov.br/explica/producao-agropecuaria/). Na produção de soja, muitos fatores influenciam o resultado, sendo vários deles incontroláveis, como fatores climáticos. Este ano, por exemplo, houve um aumento de 70,83% na produtividade em relação ao ano anterior, provavelmente relacionado ao volume de precipitação.

|       Dessa forma, torna-se necessário estimar a produtividade da soja e verificar quais são as principais variáveis que a influenciam, permitindo realizar predições da safra e estimar o potencial de produção a nível nacional.

|       Inicialmente, será realizada uma análise descritiva dos dados para compreender as variáveis envolvidas e suas inter-relações. Em seguida, o modelo de regressão linear múltipla será ajustado para identificar os fatores mais significativos que afetam a produtividade da soja. O diagnóstico de influência ajudará a identificar pontos de dados que têm um impacto desproporcional no ajuste do modelo, possibilitando a correção ou análise adicional desses pontos. Finalmente, as suposições do modelo de regressão linear serão testadas para garantir a validade das conclusões obtidas.

|       Os dados utilizados neste estudo foram disponibilizados pela empresa Crops Team e foram coletados a partir de experimentos com cultivares de soja realizados em diversos locais do estado do Rio Grande do Sul durante as safras de 2021/2022 e 2022/2023.

|       Este estudo é importante porque permite identificar os principais determinantes da produtividade da soja, fornecendo insights valiosos para a tomada de decisões agrícolas e a otimização dos rendimentos das cultivares. Ao compreender melhor os fatores que influenciam a produtividade, produtores e pesquisadores podem implementar práticas agrícolas mais eficazes.

# Dados

|       O banco de dados, inicialmente, continha informações dos 4 blocos de ensaios para cada cultivar. Posteriormente, foi calculada a média dos blocos por cultivar, resultando em 1513 observações e 33 variáveis. Entretanto, após o precesso de filtragens e tratamento de valores faltantes, esses números foram reduzidos. As variáveis do banco de dados incluem informações sobre as cultivares, características do local, dados climáticos durante o período dos experimentos e componentes químicos do solo. 

-   **Cultivares:** Informações sobre as diferentes variedades de soja utilizadas nos experimentos.

-   **Localização:** Características geográficas dos locais onde os experimentos foram conduzidos.

-   **Dados Climáticos:** Informações sobre precipitação, temperatura e outras condições climáticas durante o período dos experimentos.

-   **Componentes Químicos do Solo:** Dados sobre a composição química do solo, incluindo níveis de nutrientes e pH.


|       Dentre essas principais características, as variáveis mais significativas utilizadas no modelo foram:

1.  `Terras`: divididas em (Altas ou Baixas)
2.  `Ambiente`: dividido em (Sequeiro ou Irrigado)
3.  `Cultura_Ant`: ("arroz e pousio","aveia", "aveia branca", "aveia e centeio", "aveia e ervilhaca", "azevem", "cevada", nabo")
4.  `P_base`: Quantidade de adubação de Fósforo
5.  `N_base`: Quantidade de adubação de Nitrogênio
6.  `Produtividade`: Produtividade de soja (Kg/ha)
7.  `GMR`: Grupo de maturação relativo
8.  `Espacamento`: Espaçamento entre linhas do plantio de soja
9.  `Temperatura_Max`: média da temperatura máxima durante o périodo
10. `PH`: PH do solo
11. `M.O.(%)`: Matéria orgânica (%)
12. `Epoca_de_semeadura`: Data de plantio

```{r, warning=FALSE, include=FALSE}

dado1 <- readxl::read_xlsx("DADOS_COMPLETO_corrigido.xlsx", 
                           col_types =c(rep("text",5),"numeric",
                                        rep("text", 4), "date",                                         rep("numeric", 13)))

dado2 <- readxl::read_xlsx("DADOS_SOLOS.xlsx")


dados <- inner_join(dado1, dado2, by = c("COD_PROD", "Safra", "Local", "Ambiente", "Epoca_de_semeadura"))

```

Sendo as primeiras colunas e observações dadas por:
```{r, echo=FALSE}
# kable(head(dados, n=10), format = "html") %>%
#   kable_styling(bootstrap_options = c("bordered"), full_width = FALSE) %>%
#   row_spec(0, bold = TRUE, color = "black", background = "white") %>%
#   scroll_box(width = "100%", height = "300px")

dados |> 
  dplyr::select(1:12) |> 
  head(n = 5) |> 
  kable() |> 
  kable_styling(font_size = 10, full_width = FALSE)
```

# Análise Descritiva

|       As análises dos dados referem-se a um processo crítico em relação produtividade de soja no RS. Dessa forma, foi verificado medidas de tendência central, medidas de disperção, as relações entre as variáveis e suas distribuições.

```{r, echo=FALSE }
skim(dados) |> 
  dplyr::select(-complete_rate, -numeric.hist)

# remover hist tbm, caso não tenha espaço
```

|       Podemos verificar valores faltantes em algumas variáveis no banco de dados, dessa forma, foram retiradas essas observações devido a falta de informação para o preenchimento correto desses NA's. Além disso, podemos ter uma ideia da média e da distribuição dos dados

```{r, echo=FALSE}
dados <- na.omit(dados)

numeric_data <- dados %>% 
  select_if(is.numeric)

corr_matrix <- cor(numeric_data)

```

|       Com o gráfico a seguir, podemos verificar as principais correlações entre as variáveis numéricas e já procurar possiveis casos de multicolinearidade e variáveis que podem ser mais significativas para estimar a produtividade de soja

```{r, echo=FALSE,fig.height=10, fig.width=11, dpi=200}
corrplot(corr_matrix, method = "circle", type = "upper")
```

|       O gráfico de correlação entre as variáveis pode ser interpretado a partir do tamanho dos círculos e da cor. Quanto maior o círculo e mais escura é a cor mais forte é a correlação, também, se puxar mais para o azul é positiva, se for vermelha é negativa.

|       Principais medidas da variável de interesse e um gráfico para mostrar frequência de produtividade

**Média da produtividade:** `r round(mean(dados$Produtividade))`

**Desvio padrão da produtividade:** `r round(sd(dados$Produtividade))`

```{r, echo=FALSE, dpi= 200}
hist(dados$Produtividade,
     col="#cae9ff",
     border="black",
     xlab = "Produtividade (Kg/ha)", ylab = "Frequência",
     ylim = c(0, 150),
     main = "",
     nclass = 15)
abline(v = mean(dados$Produtividade), col = "#fb8500", lwd = 3)
legend(x="topright", c("Media"), 
       col = "#fb8500", lwd = 3) 
```

O gráfico de boxplot mostra a relação entre os anos das safras com a produtividade

```{r, dpi=200, echo=FALSE}
ggplot(dados) +
  aes(y = Produtividade, 
      fill = Safra, group = Safra) +
  geom_boxplot() +
  scale_fill_manual(values = c("#5fa8d3", "#fb8500"))+
  scale_y_continuous(expand = expansion(mult = c(0.03,0.05)),
                     breaks = c(0, 1000, 2000, 3000, 4000, 
                                5000, 6000, 7000)) +
  theme_classic() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())
```

|       Nota-se um diferença de produtividade entre as duas safras, de certa forma a variável `Safra` deveria ser significativa para a explicação da produtividade de soja, no entanto ja tem relação com outras variáveis do modelo. Além disso, deve explicar a alta variabilidade dos erros, conforme será apresentado nas suposições do modelo.


```{r, echo=FALSE, dpi=200}
dados <- dados %>%
  mutate(Local_Safra = reorder_within(Local, Produtividade, Safra))

ggplot(dados) +
  aes(y = Produtividade, x = Local_Safra, fill = Safra) +
  geom_boxplot() +
  scale_fill_manual(values = c("#5fa8d3", "#fb8500")) +
  scale_y_continuous(expand = expansion(mult = c(0.03, 0.05)),
                     breaks = c(0, 1000, 2000, 3000, 4000, 
                                5000, 6000, 7000)) +
  scale_x_reordered() +
  theme_classic() +
  labs(x = "") +
  theme(axis.text.x = element_text(angle = 45, size = 6,
                                   hjust = 1, vjust = 1, 
                                   color = "black"))
```

|       A partir do gráfico percebe-se a alta variabilidade de produtividade entre os locais de ensaio nas duas safras.

# Ajustes dos Dados

1 - Inicialmente foi removida uma cultivar experimental e cultivares com grupos de maturação relativos maiores que 7

2 - Os locais Santa Rosa e Jacutinga apresentaram ser pontos influêntes para o modelo. Logo para o ajuste foi melhor remover essas observações

3 - Locais os quais não tiveram uma cultura antes do plantio de soja ou tiveram mix também foram pontos de alavancagem para o modelo.

4 - Criação da variável `mês`, relacionada a data de plantio, ou seja, invés de ter dia e mês, tem se apenas o mês

5 - Foi alterado a variável `Terras`, em que Baixas recebe 0 e Altas recebe 1. A variável `Ambiente`, "irrigado" = 1 e "sequeiro" = 0

```{r, warning=FALSE, echo=FALSE}
dados <-  dados |> 
  filter(!Cultivar == "EXPERIMENTAL") |> 
  filter(GMR <= 7) |> 
  filter(!Produtividade == 383.250) |> 
  filter(Produtividade < 6800) |> 
  filter(!Local == "ITAQUI") |> 
  filter(!Local == "SANTA ROSA") |> 
  filter(!Cultura_Ant == "mix") |> 
  filter(!Cultura_Ant == "soja pousio") |> 
  filter(!Cultura_Ant == "pousio")

dados_backup <- dados

dados <- dados |> 
  dplyr::select(c("Terras", "Ambiente", "Cultura_Ant", "P_base", "N_base", "Produtividade", "GMR", "Espacamento", "Temperatura_Max", "PH", "M.O.(%)", "Epoca_de_semeadura"))

dados <- dados %>%
  mutate(mes = month(Epoca_de_semeadura, label = TRUE, abbr = TRUE)) %>%
  mutate(mes = as.character(mes))

dados <- dados %>%
  mutate(
    Terras = recode_factor(Terras, "BAIXAS" = "0", "ALTAS" = "1"),
    Ambiente = recode_factor(Ambiente, "IRRIGADO" = "1", "SEQUEIRO" = "0")
  ) %>%
  dplyr::select(-Epoca_de_semeadura)

```

Os dados depois de filtrados e selecionados as variáveis importantes para o modelo, é dado por:

```{r, echo=FALSE}
set.seed(8)
dados <- dados[sample(nrow(dados)), ]

kable(head(dados, n = 10)) |> 
  kable_styling(font_size = 10, full_width = FALSE)
  
```

# Modelo Ajustado

Inicialmente, foi selecionada as variáveis do modelo pelo algoritmo de Stepwise, determinando aquele com menor AIC

```{r, echo=FALSE}
fit <- lm(Produtividade ~ ., data = dados)
```

```{r, echo=FALSE}
s_fit <- summary(fit)
#print(s_fit)

#caso quisesse plotar o ajuste em tabela bunitinho

coef_df <- as.data.frame(s_fit$coefficients)

# kable(coef_df, format = "latex", booktabs = T,
#       caption = "Modelo ajustado") |>
#   kable_styling(latex_options = c("striped", "HOLD_position"))

kable(coef_df)

```

```{r, echo=FALSE}


coef <- fit$coefficients

equation <- paste("Y = ", round(coef[1], 1))

line_length <- 0
max_length <- 95


for (i in 2:length(coef)) {
  
  if(coef[i] > 0){
    term <- paste(" + ", round(coef[i], 1), " X_{", (i-1), "}",sep = "")
  } else {
    term <- paste(" ", round(coef[i], 1), " X_{", (i-1), "}",sep = "")
  }

line_length <- line_length + nchar(term)
  
  if (line_length > max_length) {
    equation <- paste0(equation, " \\\\ ", term)
    line_length <- nchar(term)  
  } else {
    equation <- paste0(equation, term)
  }
}

equation <- paste0(equation, " + \\epsilon")

```

O Modelo de regresssão linear múltipla, é expressado pela equação:

$$ Y= \beta_0 + \sum^{18}_{i=1} \beta_i X_{i} + \epsilon $$

Sendo:

$`r equation`$

Em que:

| $X_1$ = Terras, $x \in \{0, 1\}$

| $X_2$ = Ambiente, $x \in \{0, 1\}$

| $X_3$ = Aveia, $x \in \{0, 1\}$

| $X_4$ = Aveia e centeio, $x \in \{0, 1\}$

| $X_5$ = Aveia e ervilhaca, $x \in \{0, 1\}$

| $X_6$ = Azevém, $x \in \{0, 1\}$

| $X_7$ = Cevada, $x \in \{0, 1\}$

| $X_8$ = Nabo, $x \in \{0, 1\}$

| $X_9$ = Trigo, $x \in \{0, 1\}$

| $X_{10}$ = P_base, $x \in [40, 135]$

| $X_{11}$ = N_base, $x \in [5, 40]$

| $X_{12}$ = GMR, $x \in [4.9, 6.7]$

| $X_{13}$ = Espacamento, $x \in [0.4, 0.575]$

| $X_{14}$ = Temperatura_Max, $x \in [22.32, 27.07]$

| $X_{15}$ = PH, $x \in [4.8, 6.3]$

| $X_{16}$ = M.O.(%), $x \in [1, 4.2]$

| $X_{17}$ = Novembro, $x \in \{0, 1\}$

| $X_{18}$ = Dezembro, $x \in \{0, 1\}$

**Interpretação dos betas:**

-   $\beta_1$, significa que terras altas produzem `r round(coef[2],1)` kg/ha a menos que terras baixas.

-   $\beta_2$, significa que ambientes sequeiros produzem `r round(coef[3],1)` kg/ha a menos que ambientes irrigados

-   $\beta_{3}, \cdots, \beta_9$ , quanto maior o beta maior é significante para o aumento de produtividade, ou seja, neste caso o plantio de trigo antes da soja melhora a protuvidade.

-   $\beta_{10}$, a cada um 1 kg/ha de fósforo, dentro do intervalo de $X_{10}$ estabelecido, aumenta `r round(coef[11],1)` kg/ha na produtividade de soja.

-   $\beta_{11}$ a cada um 1 kg/ha de nitrogênio, dentro do intervalo de $X_{11}$ estabelecido, diminui `r round(coef[12],1)` kg/ha na produtividade de soja.

-   $\beta_{12}$, quanto maior for o GMR, maior será a produtividade

-   $\beta_{13}$, espaçamentos menores tem mais incremento na produtividade

-   $\beta_{14}$, temperaturas mais altas diminuem a produtividade.

-   $\beta_{15}$, o PH do solo tem um fator positivo na produtividade

-   $\beta_{16}$, a cada um 1% de matéria orgânica, aumenta em `r round(coef[17],1)` kg/ha de soja

-   $\beta_{17}$ e $\beta_{18}$, o plantio no mês de outubro em relação ao mês de novembro tem um acréscimo de aproximadamente 160 kg/ha.

|       O coeficiente de determinação, $R^2$, é dado por `r s_fit$r.squared`, ou seja, significa que `r round(s_fit$r.squared * 100, 1)`% da variabilidade na produtividade da soja pode ser explicada pelas variáveis incluídas no modelo de regressão.

# Analise de diagnóstico

As principais observações influentes podem ser visualizadas na tabela a seguir

```{r, echo=FALSE}
a <- influence.measures(fit)
influentes <- a$is.inf

obs_influentes <- apply(influentes, 1, any)
obs_influentes_indices <- which(obs_influentes)
dados_influentes <- dados[obs_influentes_indices, ]

kable(head(dados_influentes, n = 8)) |> 
  kable_styling(font_size = 10, full_width = FALSE)

#influencias_influentes <- a$infmat[obs_influentes_indices, ]
#print(influencias_influentes)
```

Apesar de ainda possuir pontos de influência não afetam no ajuste do modelo

## Alavancagem

```{r, echo=FALSE}
n<-dim(dados)[1] 

#hatvalues(fit)

h_bar<-fit$rank / n
limite<-2*h_bar
abline(plot(hatvalues(fit),ylab="Alavancagem"), 
       col="red", h=limite,lty=2)

#which(hatvalues(fit)>limite)
#which.max(hatvalues(fit))
```

Como de esperado ficou alguns pontos de alavancagem, mas a retirada deles não afetaram o $R^2$ do modelo

## DFFIT

```{r, echo=FALSE}
#dffits(fit)

limite<-2*sqrt(fit$rank / n)
abline(plot(dffits(fit),ylab="DFFITS"), 
       col="red", h=c(-limite,limite),lty=2)

#which(abs(dffits(fit))>limite)
```

É possível observar que alguns pontos têm valores dos DFFITS acima da linha de referência, mas após análises, eles não apresentaram influência na regressão

```{r, echo=FALSE}
## DFBETA
#dfbetas(fit) 

# limite<-2/sqrt(n)
# n_betas <- dim(dfbetas(fit))[2]
# 
# for(i in 1:n_betas){
#   
#   dfb <- dfbetas(fit)[,i]
#   
#   Ylab <- paste("DFBETA ", i)
#   
#   abline(plot(dfb,ylab= Ylab), 
#        col=c("red","blue","red"),
#        h=c(-limite,0,limite),lty=c(2,1,2))
#   
# }
```

## Distância de Cook

```{r, echo=FALSE}
#cooks.distance(fit)
limite<-4/(n-fit$rank )
abline(plot(cooks.distance(fit),ylab="Distancia de Cook"), 
       col="red", h=limite,lty=2)
```

Os mesmos pontos identificados anteriormente aparece no gráfico da distância de cook, mas a remoção dos mesmos não afeta significativamente nos coeficientes da regressão.

## Resíduo

```{r, echo=FALSE}

residuo <- rstudent(fit) # residuo studentizado

plot(residuo,type='p',pch="+",main="Resíduos",xlab="indices") 
abline(h=c(-2,0,2),lty=3)

#which(abs(residuo)>3)

hist(residuo, main = "Histograma dos resíduos", xlab = "Resíduo",
     ylab = "Frequência", col = "#cae9ff") 
```


Como esperado, a distribuição dos resíduos tende a se aproximar de uma distribuição normal com média 0. Esta suposição será verificada a seguir através de testes de normalidade.


## Envelope Simulado

Baseado nos resíduos studentizados para verificação de normalidade

```{r, echo=FALSE, results='hide'}
hnp(fit,resid.type="student",halfnormal = F)
```

A partir do gráfico podemos ver alguns pontos fora do intervalo, mas como n = `r n`, é esperado a 5% que até `r n * 0.05` pontos fiquem fora do intervale e após testes os resíduos seguem normalidade conforme é esperado.

# Suposições do modelo

-   [S0] O modelo esta corretamente específicado
-   [S1] A média dos erros é zero
-   [S2] Homoscedasticidade dos erros
-   [S3] Não autocorrelacão
-   [S4] Ausência de Multicolinearidade
-   [S5] Normalidade dos erros

## Teste RESET

$$
\begin{cases}
H_0: \textrm{O modelo esta corretamente especificado}\\
H_1: \textrm{O modelo não esta corretamente especificado}.
\end{cases}
$$

```{r, echo=FALSE}
resu <- resettest(fit)
print(resu)
```

Conforme o tese RESET, utilizado para verificar se o modelo está corretamente específicado, não rejeita-se $H_0$ devido p-valor = `r resu$p.value` \> $\alpha$ = 0.01, ou seja, O modelo esta corretamente especificado.

## Teste t para a média dos errros

$$
\begin{cases}
H_0: \textrm{ A média dos erros é igual a zero
}\\
H_1: \textrm{média dos erros é diferente de zero}.
\end{cases}
$$

```{r, echo=FALSE}
resu <- t.test(resid(fit),mu=0,alternative="two.sided")
print(resu)
```

Conforme o teste T de Student, não rejeita-se $H_0$ devido ao p-valor = `r resu$p.value` \> $\alpha$ = 0.01. Dessa forma, a média dos erros é igual a zero.

## Teste de Bressch-Pagan

$$
\begin{cases}
H_0: \textrm{ Os erros são homoscedasticos
}\\
H_1: \textrm{Os erros não são homoscedasticos}.
\end{cases}
$$

```{r, echo=FALSE}
resu <- bptest(fit, studentize = TRUE)
print(resu)
```

Conforme o teste de Breusch-Pagan, rejeita-se $H_0$ devido p-valor = `r resu$p.value` \< $\alpha$ = 0.01. Dessa forma, os erros são heteroscedasticos, não seguindo a suposição $[S2]$. O ideal para seria modelar a variância junto, já que existe muita diferença de manejo dos produtores entre os locais dos experimentos.

## Teste de Durbin-Watson

$$
\begin{cases}
H_0: \textrm{Não há autocorrelação}\\
H_1: \textrm{Há autocorrelação}.
\end{cases}
$$

```{r, echo=FALSE}
resu <- dwtest(fit)
acf(rstudent(fit))
print(resu)
```

Conforme o teste de Durbin-Watson, não rejeita-se $H_0$ devido p-valor = `r resu$p.value` \> $\alpha$ = 0.01. Ou seja, não existe multicolinealidade entre as variáveis explicativas

## Fatores de Inflação de Variância

$$
\begin{cases}
H_0: \textrm{Não há multicolinearidade}\\
H_1: \textrm{Há multicolinearidade}.
\end{cases}
$$

```{r, echo=FALSE}
df <- vif(fit)

kable(head(df, n = 11), format = "html") %>%
  kable_styling(font_size = 12,bootstrap_options = c("bordered"), full_width = FALSE) %>%
  row_spec(0, bold = TRUE, color = "black", background = "white")
```

Interpretação:

|       vif maior que 10 indica multicolinearidade,  vif próximo de 1 seria o ideal.

Dessa forma, todos os valores estão próximos de 1 indicando o indício de não multicolinearidade

## Teste Jarque-Bera

$$
\begin{cases}
H_0: \textrm{Os erros possuem distribuição normal}\\
H_1: \textrm{Os erros não possuem distribuição normal}.
\end{cases}
$$

```{r, echo=FALSE}
resu <- jarque.bera.test(resid(fit))
print(resu)
```

Conforme o teste de Jarque-Bera, não rejeita-se $H_0$ devido ao p-valor = `r resu$p.value`\$ \> \alpha = 0.01\$. Ou seja, os erros possuem distribuição normal

# Predição

|       Dado que as suposições do modelo foram satisfeitas, podemos realizar inferências e predições sobre a variável resposta. Abaixo, é apresentado uma tabela com valores aleatórios,dentro do espaço amostral, para as variáveis significativas do modelo e assim, realizar a predição da produtividade média.

```{r, echo=FALSE}

nomes <- names(dados)
nomes <- setdiff(nomes, "Produtividade")

novos_dados <- data.frame(matrix(ncol = length(nomes),
                           nrow = 0))

valores1 <- c(1, 0, "aveia", 70, 10, 5, 0.5, 25, 5, 2,"nov")
valores2 <- c(1, 1, "cevada", 80, 6, 6, 0.45, 26, 7, 3,"out")
valores3 <- c(0, 0, "aveia e ervilhaca", 75, 7, 5.5, 0.45, 26, 8, 4,"dez")


novos_dados <- rbind(novos_dados, valores1, valores2,valores3)

colnames(novos_dados) <- nomes

novos_dados <- novos_dados |> 
  mutate(P_base = as.numeric(P_base),
         N_base = as.numeric(N_base),
         GMR = as.numeric(GMR),
         Espacamento = as.numeric(Espacamento),
         Temperatura_Max = as.numeric(Temperatura_Max),
         PH = as.numeric(PH),
         `M.O.(%)` = as.numeric(`M.O.(%)`))


a <- predict(fit, newdata=novos_dados) 
novos_dados <- cbind(novos_dados, Predicao = a) 

kable(head(novos_dados, n=10), format = "html",
      caption = "Novos Dados e Predição") %>%
  kable_styling(font_size = 12,bootstrap_options = c("bordered"), full_width = FALSE) %>%
  row_spec(0, bold = TRUE, color = "black", background = "white") #%>%
  #scroll_box(width = "100%", height = "300px")

```

O gráfivo a seguir mostra a relação entre os valores reais de produtividade, com os valores preditos a partir do modelo de regressão.

```{r, echo=FALSE, dpi=200}
preditos <- predict(fit)

dado_graf <- data.frame(
  real = dados$Produtividade,
  predito = preditos
)

#dado_graf <- dado_graf[order(dado_graf$real), ]

dado_graf$indice <- 1:nrow(dado_graf)

ggplot(dado_graf, aes(x = indice)) +
  geom_point(aes(y = real, color = "Reais")) +
  geom_point(aes(y = predito, color = "Preditos")) +
  scale_color_manual(values = c("Reais" = "#5fa8d3",
                                "Preditos" = "#fb8500")) +
  labs(x = "Índices", y = "Produtividade",
       color = "Legenda") +
  theme_minimal()
```


# Conclusão

|       De acordo com a análise de regressão, as principais variáveis que influenciam na produtividade da soja neste banco de dados são o tipo de terras e ambiente, o espaçamento entre linhas, a temperatura máxima durante o período de crescimento, o pH do solo e o teor de matéria orgânica. Além disso, práticas agrícolas como a escolha da cultura anterior e a quantidade de adubação com fósforo e nitrogênio também mostraram impacto significativo.

|       A análise diagnóstica do modelo identificou alguns pontos influentes e de alavancagem, mas estes não comprometeram significativamente a qualidade do ajuste. A verificação das suposições do modelo mostrou que a maioria foi atendida, exceto pela homoscedasticidade dos erros, indicando a presença de heteroscedasticidade. Isso sugere que este não é o melhor modelo, mas ainda oferece insights valiosos sobre os fatores que afetam a produtividade da soja.

# Trabalhos futuros

- Modelar a variância 

- Remover pelo menos uma safra, em locais que foi realizado os ensaios em mais de um ano, para assim, evitar possível dependência temporal.

- Usar todos os blocos invés da média deles

- Pensar em uma forma de definir todos os dias de plantio

- Usar as coordenadas geográficas dos local como variáveis

```{r, echo=FALSE}
#pagedown::chrome_print("Trabalho_Reg.html")
```
